\chapter{Hardware Implementierung}

\section{Komponenten}

\begin{itemize}
    \item{Raspberry Pi 4 1 GB}
    \item{COEX Clover 4.2}
\end{itemize}

\section{COEX Clover 4.2}

\subsection{Abstandssensor}

\subsection{PX4 FlightController}

\begin{itemize}
    \item{Barometer}
    \item{Gyroskop}
    \item{Accelerometer}
    \item{Magnetometer}
\end{itemize}

\subsection{Kamera}

\section{3D Scanner}
In der heutigen Zeit gibt es viele verschiedene Geräte, welche man als 3D-Scanner bezeichnen kann. Jedes Gerät, das die physische Welt mit Hilfe von Lasern, Licht oder Röntgenstrahlen misst und dichte Punktwolken oder Polygonnetze erzeugt, kann als 3D-Scanner betrachtet werden. Allerdings haben alle diese Verschiedenen Geräte unterschiedliche Namne, wie z.b. Laserscanner, Weißlichtscanner oder auch 3D-Digitalisierer. Was diese Geräte gemeinsam haben ist der Fakt, dass sie die Geometrie von physischen Objekten mit Hunderttausenden oder sogar Millionen von Messungen erfassen und man diese Objekte somit digital darstellen kann.

\subsection{Funktionsweise 3D-Scanner}
Wie bereits erwähnt existieren viele verschiedene Ansätze für das 3D-Scannen, die auf unterschiedlichen Prinzipien der Bildgebung basieren. 3D-Scanner mit weniger als einem Meter Brennweite umfassen 3D-Scanner, die mit Lasertriangulation bzw. strukturiertem Licht arbeiten.

\subsubsection{Lasertriangulation}
Die Lasertriangulation gehört zu den optischen Entfernungsmessmethoden. Hierbei wird ein oder mehrere Laserstahlen auf einen Gegenstand von einem entsprechendem Sender geworfen.

Zu den optischen Entfernungsmessmethoden gehört die Lasertriangulation. Beim Auftreffen auf das Werkstück wird die Laserstrahlung diffus reflektiert und am Detektor hinsichtlich der Intensität und ihrer Verteilung ausgewertet. Zwischen der einfallenden und der diffus reflektierten Wellennormale lassen sich Winkelgrößen ermitteln, die als Grundlage für die Abstandsberechnung dienen. [2] Fällt die Laserstrahlung nach einem veränderten Weg auf die Oberfläche auf, kommt es zu einer Verschiebung des Bildpunktes. Bei einer Neigung des Detektors gegen die Mittelachse der Linse ist eine scharfe Abbildung möglich. Dabei müssen die Mittelachse der Linse (in Abb. 5: uAchse), die Ebene der Oberfläche des Detektors und die Wellennormale des Laserstrahls einen gemeinsamen Schnittpunkt aufwiesen, was Scheimpflug-Bedingung genannt wird. Diese Bedingung kann für beliebige Neigungen des Objektivs erfüllt sein. Daher können auf Triangulation beruhende Systeme so kompakt gebaut werden, dass sie ebenso wie Laufzeitmessgeräte in handelsüblichen Entfernungsmessern vertreten sind. Die Bildkoordinate z‘ ist nahezu linear von der Koordinate z des Leuchtflecks abhängig und die zugehörige Gleichung lautet


\subsection{Microsoft Hololens}
Bei echten Augmented-Reality-Geräten wie Hololens scannt und verarbeitet die AR-Brille die Umgebung in Echtzeit. Dafür hat Hololens eine Reihe an 3D-Tiefenkameras im Gehäuse verbaut. Angeblich handelt es sich dabei um stark angepasste Ableger von Intels Realsense-Technologie. Herkömmliche RGB-Kameras ergänzen Farbinformationen und Textur.

Basierend auf den Kameradaten kann Hololens nicht nur Hologramm-ähnliche Abbildungen perspektivisch korrekt in den Raum projizieren, sondern den Raum als solches als 3D-Modell rekonstruieren. Das einmal erfasste Modell kann dann sowohl mit Hololens dargestellt als auch mit anderen Programmen weiterverarbeitet werden.

\subsection{Microsoft Azure Kinect}